{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from  sklearn import metrics\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"x_train.csv\")#read input data\n",
    "y_train = pd.read_csv(\"y_train.csv\")#read input data\n",
    "x_test = pd.read_csv(\"x_test.csv\")#read input data\n",
    "y_test = pd.read_csv(\"y_test.csv\")#read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(columns=x_train.columns[0], axis=1, inplace=True)\n",
    "y_train.drop(columns=y_train.columns[0], axis=1, inplace=True)\n",
    "x_test.drop(columns=x_test.columns[0], axis=1, inplace=True)\n",
    "y_test.drop(columns=y_test.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ran in 0.0110 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "RandomForest = RandomForestClassifier(n_estimators=1, max_depth=3)\n",
    "RandomForest.fit(x_train, y_train.values.ravel())\n",
    "toc = time.perf_counter()\n",
    "print(f\"Model Ran in {toc - tic:0.4f} seconds\")\n",
    "prediction = RandomForest.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision Accuracy Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8716475095785441\n",
      "Recall - Macro: 0.7054296257248287\n",
      "Precision - Macro: 0.708843537414966\n",
      "Recall - Micro: 0.8716475095785441\n",
      "Precision - Micro: 0.8716475095785441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajaym\\miniconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, prediction))\n",
    "print(\"Recall - Macro:\", metrics.recall_score(y_test, prediction, average=\"macro\"))\n",
    "print(\"Precision - Macro:\", metrics.precision_score(y_test, prediction, average=\"macro\"))\n",
    "print(\"Recall - Micro:\", metrics.recall_score(y_test, prediction, average=\"micro\"))\n",
    "print(\"Precision - Micro:\", metrics.precision_score(y_test, prediction, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    632\n",
      "1    262\n",
      "4    186\n",
      "3    119\n",
      "2     17\n",
      "Name: QOL_Measure, dtype: int64\n",
      "5    271\n",
      "1    112\n",
      "4     80\n",
      "3     52\n",
      "2      7\n",
      "Name: QOL_Measure, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.QOL_Measure.value_counts())\n",
    "print(y_test.QOL_Measure.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement SMOTE on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "x_res, y_res = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Class Distribution After SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    632\n",
      "3    632\n",
      "4    632\n",
      "2    632\n",
      "1    632\n",
      "Name: QOL_Measure, dtype: int64\n",
      "5    271\n",
      "1    112\n",
      "4     80\n",
      "3     52\n",
      "2      7\n",
      "Name: QOL_Measure, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_res.QOL_Measure.value_counts())\n",
    "print(y_test.QOL_Measure.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ran in 0.0243 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "RandomForestSmote = RandomForestClassifier(n_estimators=3, max_depth=3)\n",
    "RandomForestSmote.fit(x_res, y_res.values.ravel())\n",
    "toc = time.perf_counter()\n",
    "print(f\"Model Ran in {toc - tic:0.4f} seconds\")\n",
    "predictionSmote = RandomForestSmote.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Precision Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9176245210727969\n",
      "Recall - Macro: 0.9209290985767001\n",
      "Precision - Macro: 0.7923214285714286\n",
      "Recall - Micro: 0.9176245210727969\n",
      "Precision - Micro: 0.9176245210727969\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictionSmote))\n",
    "print(\"Recall - Macro:\", metrics.recall_score(y_test, predictionSmote, average=\"macro\"))\n",
    "print(\"Precision - Macro:\", metrics.precision_score(y_test, predictionSmote, average=\"macro\"))\n",
    "print(\"Recall - Micro:\", metrics.recall_score(y_test, predictionSmote, average=\"micro\"))\n",
    "print(\"Precision - Micro:\", metrics.precision_score(y_test, predictionSmote, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Reduced Data Set and Apply Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reduced = pd.read_csv(\"x_train_reduced.csv\")#read input data\n",
    "y_train_reduced = pd.read_csv(\"y_train_reduced.csv\")#read input data\n",
    "x_test_reduced = pd.read_csv(\"x_test_reduced.csv\")#read input data\n",
    "y_test_reduced = pd.read_csv(\"y_test_reduced.csv\")#read input data\n",
    "\n",
    "x_train_reduced.drop(columns=x_train_reduced.columns[0], axis=1, inplace=True)\n",
    "y_train_reduced.drop(columns=y_train_reduced.columns[0], axis=1, inplace=True)\n",
    "x_test_reduced.drop(columns=x_test_reduced.columns[0], axis=1, inplace=True)\n",
    "y_test_reduced.drop(columns=y_test_reduced.columns[0], axis=1, inplace=True)\n",
    "\n",
    "sm_reduced = SMOTE(random_state=42)\n",
    "x_res_reduced, y_res_reduced = sm_reduced.fit_resample(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ran in 0.0159 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "RandomForestSmoteReduced = RandomForestClassifier(n_estimators=3, max_depth=3)\n",
    "RandomForestSmoteReduced.fit(x_res_reduced, y_res_reduced.values.ravel())\n",
    "toc = time.perf_counter()\n",
    "print(f\"Model Ran in {toc - tic:0.4f} seconds\")\n",
    "predictionSmoteReduced = RandomForestSmoteReduced.predict(x_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision Accuracy Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9272030651340997\n",
      "Recall - Macro: 0.9395730100158144\n",
      "Precision - Macro: 0.8366060606060607\n",
      "Recall - Micro: 0.9272030651340997\n",
      "Precision - Micro: 0.9272030651340997\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_reduced, predictionSmoteReduced))\n",
    "print(\"Recall - Macro:\", metrics.recall_score(y_test_reduced, predictionSmoteReduced, average=\"macro\"))\n",
    "print(\"Precision - Macro:\", metrics.precision_score(y_test_reduced, predictionSmoteReduced, average=\"macro\"))\n",
    "print(\"Recall - Micro:\", metrics.recall_score(y_test_reduced, predictionSmoteReduced, average=\"micro\"))\n",
    "print(\"Precision - Micro:\", metrics.precision_score(y_test_reduced, predictionSmoteReduced, average=\"micro\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80e4160372489fecbd775fbd24446e111a2a40cc60fb901013a1d683c4042b3f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
